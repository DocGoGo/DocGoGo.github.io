<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CKA-kubernetes-第二章 | 欢迎来到李维虎的在线博客</title><meta name="author" content="李维虎"><meta name="copyright" content="李维虎"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Kubernetes概述​	Kubernetes 是一个可移植、可扩展的开源平台，用于管理容器化的工作负载和服务，方便进行声明式配置和自动化。Kubernetes 拥有一个庞大且快速增长的生态系统，其服务、支持和工具的使用范围广泛。 ​	Kubernetes 这个名字源于希腊语，意为“舵手”或“飞行员”。K8s 这个缩写是因为 K 和 s 之间有 8 个字符的关系。 Google 在 2014 年">
<meta property="og:type" content="article">
<meta property="og:title" content="CKA-kubernetes-第二章">
<meta property="og:url" content="http://example.com/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/index.html">
<meta property="og:site_name" content="欢迎来到李维虎的在线博客">
<meta property="og:description" content="Kubernetes概述​	Kubernetes 是一个可移植、可扩展的开源平台，用于管理容器化的工作负载和服务，方便进行声明式配置和自动化。Kubernetes 拥有一个庞大且快速增长的生态系统，其服务、支持和工具的使用范围广泛。 ​	Kubernetes 这个名字源于希腊语，意为“舵手”或“飞行员”。K8s 这个缩写是因为 K 和 s 之间有 8 个字符的关系。 Google 在 2014 年">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/doc_img/Kubernetes.webp">
<meta property="article:published_time" content="2025-07-03T01:40:06.000Z">
<meta property="article:modified_time" content="2025-07-14T02:50:22.322Z">
<meta property="article:author" content="李维虎">
<meta property="article:tag" content="Kubernetes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/doc_img/Kubernetes.webp"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "CKA-kubernetes-第二章",
  "url": "http://example.com/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/",
  "image": "http://example.com/img/doc_img/Kubernetes.webp",
  "datePublished": "2025-07-03T01:40:06.000Z",
  "dateModified": "2025-07-14T02:50:22.322Z",
  "author": [
    {
      "@type": "Person",
      "name": "李维虎",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/index_img/logo.png"><link rel="canonical" href="http://example.com/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: '',
  enable_page_level_ads: 'true'
});</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CKA-kubernetes-第二章',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (true) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/head/head.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(img/doc_img/Kubernetes.webp);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/index_img/butterfly-icon.png" alt="Logo"></a><a class="nav-page-title" href="/"><span class="site-name">CKA-kubernetes-第二章</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">CKA-kubernetes-第二章<a class="post-edit-link" href="null_posts/03-Kubernetes/CKA-kubernetes-第二章.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-03T01:40:06.000Z" title="发表于 2025-07-03 09:40:06">2025-07-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-14T02:50:22.322Z" title="更新于 2025-07-14 10:50:22">2025-07-14</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Kubernetes/">Kubernetes</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">10.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>41分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Kubernetes概述"><a href="#Kubernetes概述" class="headerlink" title="Kubernetes概述"></a>Kubernetes概述</h1><p>​	Kubernetes 是一个可移植、可扩展的开源平台，用于管理容器化的工作负载和服务，方便进行声明式配置和自动化。Kubernetes 拥有一个庞大且快速增长的生态系统，其服务、支持和工具的使用范围广泛。</p>
<p>​	<strong>Kubernetes</strong> 这个名字源于希腊语，意为“舵手”或“飞行员”。K8s 这个缩写是因为 K 和 s 之间有 8 个字符的关系。 Google 在 2014 年开源了 Kubernetes 项目。 Kubernetes 建立在 <a target="_blank" rel="noopener" href="https://research.google/pubs/pub43438">Google 大规模运行生产工作负载十几年经验</a>的基础上， 结合了社区中最优秀的想法和实践。</p>
<h2 id="什么是Kubernetes"><a href="#什么是Kubernetes" class="headerlink" title="什么是Kubernetes"></a>什么是Kubernetes</h2><p>​	Kubernetes是一个可移植、可扩展的开源容器管理平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。Kubernetes拥有一个庞大且快速增长的生态系统。</p>
<p>​	它是由Google开发并开源的项目，现由云原生计算基金会（CNCF）维护，支持跨主机集群的容器化应用管理，提供负载均衡、自我修复、自动部署和存储编排等功能。</p>
<p>​	从Kubernetes的图标看，这个图标很像一艘船的船舵，控制着船行驶的方向。</p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250703101842759.png" alt="image-20250703101842759"></p>
<p>​	再看docker的图标，类似一艘轮船（运行时），轮船上放着许多集装箱（容器），前面我们了解了一些docker的基础，现在我们要学习Kubernetes。</p>
<p>​	就好比原先你是一个吭哧吭哧打工搬运集装箱上船的员工，由于你的出色表现得到董事长的赏识，董事长把你从搬运工提升为掌舵的小领导，以后你再也不用亲历亲为去做具体的事情了，再也不用想着我要怎么把集装箱（容器）搬上船了，以后您只用下达指令你的监工们去替你督促和管理你的搬运工去做具体的事情，从此走上人生巅峰迎娶白富美。</p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250703102753594.png" alt="image-20250703102753594"></p>
<h2 id="Kubernetes的历史背景"><a href="#Kubernetes的历史背景" class="headerlink" title="Kubernetes的历史背景"></a>Kubernetes的历史背景</h2><p>​	让我们回顾一下为何 Kubernetes 能够裨益四方。</p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250703104143438.png" alt="image-20250703104143438"></p>
<p><strong>传统部署时代：</strong></p>
<p>​	早期，各个组织是在物理服务器上运行应用程序。 由于无法限制在物理服务器中运行的应用程序资源使用，因此会导致资源分配问题。 例如，如果在同一台物理服务器上运行多个应用程序， 则可能会出现一个应用程序占用大部分资源的情况，而导致其他应用程序的性能下降。 一种解决方案是将每个应用程序都运行在不同的物理服务器上， 但是当某个应用程序资源利用率不高时，剩余资源无法被分配给其他应用程序， 而且维护许多物理服务器的成本很高。</p>
<p><strong>虚拟化部署时代：</strong></p>
<p>​	因此，虚拟化技术被引入了。虚拟化技术允许你在单个物理服务器的 CPU 上运行多台虚拟机（VM）。 虚拟化能使应用程序在不同 VM 之间被彼此隔离，且能提供一定程度的安全性， 因为一个应用程序的信息不能被另一应用程序随意访问。</p>
<p>​	虚拟化技术能够更好地利用物理服务器的资源，并且因为可轻松地添加或更新应用程序， 而因此可以具有更高的可扩缩性，以及降低硬件成本等等的好处。 通过虚拟化，你可以将一组物理资源呈现为可丢弃的虚拟机集群。</p>
<p>​	每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。</p>
<p><strong>容器部署时代：</strong></p>
<p>​	容器类似于 VM，但是更宽松的隔离特性，使容器之间可以共享操作系统（OS）。 因此，容器比起 VM 被认为是更轻量级的。且与 VM 类似，每个容器都具有自己的文件系统、CPU、内存、进程空间等。 由于它们与基础架构分离，因此可以跨云和 OS 发行版本进行移植。</p>
<p>​	容器因具有许多优势而变得流行起来，例如：</p>
<ul>
<li><p>敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。</p>
</li>
<li><p>持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性）， 提供可靠且频繁的容器镜像构建和部署。</p>
</li>
<li><p>关注开发与运维的分离：在构建、发布时创建应用程序容器镜像，而不是在部署时， 从而将应用程序与基础架构分离。</p>
</li>
<li><p>可观察性：不仅可以显示 OS 级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。</p>
</li>
<li><p>跨开发、测试和生产的环境一致性：在笔记本计算机上也可以和在云中运行一样的应用程序。</p>
</li>
<li><p>跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。</p>
</li>
<li><p>以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。</p>
</li>
<li><p>松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。</p>
</li>
<li><p>资源隔离：可预测的应用程序性能。</p>
</li>
<li><p>资源利用：高效率和高密度。</p>
</li>
</ul>
<h2 id="Kubernetes特点"><a href="#Kubernetes特点" class="headerlink" title="Kubernetes特点"></a>Kubernetes特点</h2><p>​	Kubernetes具有以下几个特点：</p>
<ul>
<li>可移植：支持公有云、私有云、混合云、多重云（multi-cloud）</li>
<li>可扩展：模块化、插件化、可挂载、可组合</li>
<li>自动化：自动部署、自动修复、自动重启、自动复制、自动伸缩&#x2F;扩展</li>
</ul>
<h2 id="Kubernetes作用"><a href="#Kubernetes作用" class="headerlink" title="Kubernetes作用"></a>Kubernetes作用</h2><p>​	容器是打包和运行应用程序的好方式。在生产环境中， 你需要管理运行着应用程序的容器，并确保服务不会下线。 例如，如果一个容器发生故障，则你需要启动另一个容器。 如果此行为交由给系统处理，是不是会更容易一些？</p>
<p>​	这就是 Kubernetes 要来做的事情！ Kubernetes 为你提供了一个可弹性运行分布式系统的框架。 Kubernetes 会满足你的扩展要求、故障转移你的应用、提供部署模式等。 例如，Kubernetes 可以轻松管理系统的 Canary (金丝雀) 部署。</p>
<p>Kubernetes 为你提供：</p>
<ul>
<li><p><strong>服务发现和负载均衡</strong></p>
<p>Kubernetes 可以使用 DNS 名称或自己的 IP 地址来暴露容器。 如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p>
</li>
<li><p><strong>存储编排</strong></p>
<p>Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。</p>
</li>
<li><p><strong>自动部署和回滚</strong></p>
<p>你可以使用 Kubernetes 描述已部署容器的所需状态， 它可以以受控的速率将实际状态更改为期望状态。 例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。</p>
</li>
<li><p><strong>自动完成装箱计算</strong></p>
<p>你为 Kubernetes 提供许多节点组成的集群，在这个集群上运行容器化的任务。 你告诉 Kubernetes 每个容器需要多少 CPU 和内存 (RAM)。 Kubernetes 可以将这些容器按实际情况调度到你的节点上，以最佳方式利用你的资源。</p>
</li>
<li><p><strong>自我修复</strong></p>
<p>Kubernetes 将重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器， 并且在准备好服务之前不将其通告给客户端。</p>
</li>
<li><p><strong>密钥与配置管理</strong></p>
<p>Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 SSH 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p>
</li>
<li><p><strong>批处理执行</strong> 除了服务外，Kubernetes 还可以管理你的批处理和 CI（持续集成）工作负载，如有需要，可以替换失败的容器。</p>
</li>
<li><p><strong>水平扩缩</strong> 使用简单的命令、用户界面或根据 CPU 使用率自动对你的应用进行扩缩。</p>
</li>
<li><p><strong>IPv4&#x2F;IPv6 双栈</strong> 为 Pod（容器组）和 Service（服务）分配 IPv4 和 IPv6 地址。</p>
</li>
<li><p><strong>为可扩展性设计</strong> 在不改变上游源代码的情况下为你的 Kubernetes 集群添加功能。</p>
</li>
</ul>
<h2 id="Kubernetes整体框架"><a href="#Kubernetes整体框架" class="headerlink" title="Kubernetes整体框架"></a>Kubernetes整体框架</h2><p>​	Kubernetes 集群由一个控制平面和一组用于运行容器化应用的工作机器组成， 这些工作机器称作节点（Node）。每个集群至少需要一个工作节点来运行 Pod。</p>
<p>​	工作节点托管着组成应用负载的 Pod。控制平面管理集群中的工作节点和 Pod。 在生产环境中，控制平面通常跨多台计算机运行，而一个集群通常运行多个节点，以提供容错和高可用。</p>
<p>​	K8s整体需要至少一个Master节点和至少一个Node节点，所以要使用K8s我们至少需要两台服务器。</p>
<p>​	Master节点又称为控制平面，这里主要是我们的船长控制室也就是管理员的负责向Node节点下发指令的地方；Node节点也就是具体工人的工作室，Node节点同时会有一个监工小组长的角色（Kubelet），负责监督具体干活的Docker是否正在努力的工作。</p>
<p>​	使用Docker的时候我们指的是一个容器，而到了K8s这个概念变了，既然是集群，那么我们一个容器服务不能只有一个容器，不然达不到多负载、伸缩扩展的要求，例如一个nginx服务会生成多个容器，多个容器组成一个Pod的概念。</p>
<p>​	本文概述了构建一个完整且可运行的 Kubernetes 集群所需的各种组件。</p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250703112645294.png" alt="image-20250703112645294"></p>
<h3 id="控制平面组件"><a href="#控制平面组件" class="headerlink" title="控制平面组件"></a>控制平面组件</h3><p>​	控制平面组件会为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件，例如当不满足 Deployment 的 <code>replicas</code> （一个Pod扩展容器的数量）字段时，要启动新的Pod。</p>
<p>​	控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，安装脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户的服务容器。</p>
<h4 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h4><p>​	API 服务器是 Kubernetes 控制平面的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。API 服务器是 Kubernetes 控制平面的前端。</p>
<p>​	Kubernetes API 服务器的主要实现是 kube-apiserver。 <code>kube-apiserver</code> 设计上考虑了水平扩缩，也就是说，它可通过部署多个实例来进行扩缩。 你可以运行 <code>kube-apiserver</code> 的多个实例，并在这些实例之间平衡流量，这就是高级篇多Master节点实现高可用的K8s集群。</p>
<h4 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h4><p>​	一致且高可用的键值存储，用作 Kubernetes 所有集群数据的后台数据库，主要记录着集群中由多少个Pod现在分别部署在那几个Node节点中等等集群数据。</p>
<p>​	如果你的 Kubernetes 集群使用 etcd 作为其后台数据库， 请确保你针对这些数据有一份备份计划。</p>
<h4 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h4><p>​	<code>kube-scheduler</code> 是控制平面的组件， 负责监视新创建的、根据自身的算法来为容器服务指定Pod应该运行在哪个Node节点上为最适合的。选择节点来让 Pod 在上面运行。</p>
<p>​	调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。</p>
<h4 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h4><p>​	kube-controller-manager 是控制平面的组件， 负责运行控制器进程。</p>
<p>从逻辑上讲， 每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在同一个进程中运行。</p>
<p>​	控制器有许多不同类型。以下是一些例子：</p>
<ul>
<li>Node 控制器：负责在节点出现故障时进行通知和响应</li>
<li>Job 控制器：监测代表一次性任务的 Job 对象，然后创建 Pod 来运行这些任务直至完成</li>
<li>EndpointSlice 控制器：填充 EndpointSlice 对象（以提供 Service 和 Pod 之间的链接）。</li>
<li>ServiceAccount 控制器：为新的命名空间创建默认的 ServiceAccount。</li>
</ul>
<h4 id="cloud-controller-manager"><a href="#cloud-controller-manager" class="headerlink" title="cloud-controller-manager"></a>cloud-controller-manager</h4><p>​	一个 Kubernetes 控制平面组件， 嵌入了特定于云平台的控制逻辑。 云控制器管理器（Cloud Controller Manager）允许将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。</p>
<p><code>cloud-controller-manager</code> 仅运行特定于云平台的控制器。 因此如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的集群不包含云控制器管理器。</p>
<p>​	与 <code>kube-controller-manager</code> 类似，<code>cloud-controller-manager</code> 将若干逻辑上独立的控制回路组合到同一个可执行文件中，以同一进程的方式供你运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。</p>
<p>下面的控制器都包含对云平台驱动的依赖：</p>
<ul>
<li>Node 控制器：用于在节点终止响应后检查云平台以确定节点是否已被删除</li>
<li>Route 控制器：用于在底层云基础架构中设置路由</li>
<li>Service 控制器：用于创建、更新和删除云平台上的负载均衡器</li>
</ul>
<h3 id="节点组件"><a href="#节点组件" class="headerlink" title="节点组件"></a>节点组件</h3><p>节点组件会在每个Node节点上运行，负责维护运行的 Pod 并提供 Kubernetes 运行时环境。</p>
<h4 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h4><p><code>kubelet</code> 会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod中。</p>
<p>kubelet接收一组通过各类机制提供给它的 PodSpec，确保这些 PodSpec 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。</p>
<h4 id="kube-proxy（可选）"><a href="#kube-proxy（可选）" class="headerlink" title="kube-proxy（可选）"></a>kube-proxy（可选）</h4><p>​	kube-proxy是集群中每个节点（node）上所运行的网络代理， 实现 Kubernetes 服务（Service）概念的一部分。</p>
<p>​	kube-proxy 维护节点上的一些网络规则， 这些网络规则会允许从集群内部或外部的网络会话与 Pod 进行网络通信。</p>
<p>​	如果操作系统提供了可用的数据包过滤层，则 kube-proxy 会通过它来实现网络规则。 否则，kube-proxy 仅做流量转发。</p>
<p>​	如果你使用网络插件为 Service 实现本身的数据包转发， 并提供与 kube-proxy 等效的行为，那么你不需要在集群中的节点上运行 kube-proxy。</p>
<h4 id="容器运行时"><a href="#容器运行时" class="headerlink" title="容器运行时"></a>容器运行时</h4><p>​	这个基础组件使 Kubernetes 能够有效运行容器。 它负责管理 Kubernetes 环境中容器的执行和生命周期。</p>
<p>​	Kubernetes 支持许多容器运行环境，例如 containerd、 CRI-O以及 Kubernetes CRI、CRI-docker (容器运行环境接口) 的其他任何实现。</p>
<h2 id="Kubernetes常用插件"><a href="#Kubernetes常用插件" class="headerlink" title="Kubernetes常用插件"></a>Kubernetes常用插件</h2><p>​	插件使用 Kubernetes 资源（DaemonSet、 Deployment 等)实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于 <code>kube-system</code> 命名空间。</p>
<h3 id="Core-DNS"><a href="#Core-DNS" class="headerlink" title="Core-DNS"></a>Core-DNS</h3><p>​	尽管该插件都并非严格意义上的必需组件，但几乎所有 Kubernetes 集群都应该有集群 DNS， 因为很多示例都需要 DNS 服务。</p>
<p>​	集群 DNS 是一个 DNS 服务器，和环境中的其他 DNS 服务器一起工作，它为 Kubernetes 服务提供 DNS 记录。</p>
<p>​	Kubernetes 启动的容器自动将此 DNS 服务器包含在其 DNS 搜索列表中。</p>
<h3 id="Web-界面（仪表盘）"><a href="#Web-界面（仪表盘）" class="headerlink" title="Web 界面（仪表盘）"></a>Web 界面（仪表盘）</h3><p>​	Dashboard是 Kubernetes 集群的通用的、基于 Web 的用户界面。 它使用户可以管理集群中运行的应用程序以及集群本身，并进行故障排除。</p>
<h3 id="容器资源监控"><a href="#容器资源监控" class="headerlink" title="容器资源监控"></a>容器资源监控</h3><p>​	容器资源监控 将关于容器的一些常见的时序度量值保存到一个集中的数据库中，并提供浏览这些数据的界面。</p>
<h3 id="集群层面日志"><a href="#集群层面日志" class="headerlink" title="集群层面日志"></a>集群层面日志</h3><p>​	集群层面日志机制负责将容器的日志数据保存到一个集中的日志存储中， 这种集中日志存储提供搜索和浏览接口。</p>
<h3 id="网络插件"><a href="#网络插件" class="headerlink" title="网络插件"></a>网络插件</h3><p>​	网络插件是实现容器网络接口（CNI）规范的软件组件。它们负责为 Pod 分配 IP 地址，并使这些 Pod 能在集群内部相互通信。</p>
<h1 id="部署Kubernetes"><a href="#部署Kubernetes" class="headerlink" title="部署Kubernetes"></a>部署Kubernetes</h1><h2 id="环境介绍"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍</h2><table>
<thead>
<tr>
<th></th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td><strong>操作系统</strong></td>
<td>RedHat 9.4</td>
</tr>
<tr>
<td><strong>节点数量</strong></td>
<td>至少2，本示例为3</td>
</tr>
<tr>
<td><strong>CPU</strong></td>
<td>至少2核心，本示例为4核心</td>
</tr>
<tr>
<td><strong>内存</strong></td>
<td>至少2G，本实例为8G</td>
</tr>
<tr>
<td><strong>磁盘</strong></td>
<td>100G</td>
</tr>
<tr>
<td><strong>网络</strong></td>
<td>公网和内网均可，只要3台彼此能够互联</td>
</tr>
<tr>
<td><strong>其他</strong></td>
<td>各节点主机名、MAC地址、product_uuid不可重复，如果使用VMware虚拟机避免使用克隆</td>
</tr>
</tbody></table>
<p><strong>IP规划</strong></p>
<table>
<thead>
<tr>
<th>节点名称</th>
<th>IP</th>
</tr>
</thead>
<tbody><tr>
<td>Master-01</td>
<td>192.168.8.136</td>
</tr>
<tr>
<td>Node-01</td>
<td>192.168.8.137</td>
</tr>
<tr>
<td>Node-02</td>
<td>192.168.8.138</td>
</tr>
</tbody></table>
<h2 id="环境初始化"><a href="#环境初始化" class="headerlink" title="环境初始化"></a>环境初始化</h2><p><strong>关闭Swap分区</strong></p>
<p>​	需在三个节点都要执行关闭</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# swapoff -a</span><br><span class="line">[root@localhost ~]# sed -i <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span><br></pre></td></tr></table></figure>



<p><strong>开启iptables 检查桥接流量</strong></p>
<p>​	需在三个节点都要执行开启</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# <span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/modules-load.d/k8s.conf</span></span><br><span class="line"><span class="string">br_netfilter</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">modprobe br_netfilter</span><br><span class="line"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/sysctl.d/k8s.conf</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1</span></span><br><span class="line"><span class="string">net.ipv4.ip_forward = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">...忽略....</span><br><span class="line">[root@localhost ~]# <span class="built_in">sudo</span> sysctl --system</span><br><span class="line">* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...</span><br><span class="line">...忽略....</span><br><span class="line"><span class="comment"># 验证net.ipv4.ip_forward 是否设置为 1</span></span><br><span class="line">[root@localhost ~]# sysctl net.ipv4.ip_forward</span><br></pre></td></tr></table></figure>



<p><strong>配置主机名</strong></p>
<p>​	需在三个节点都要执行配置，可根据自身需要自行定义主机名，各节点主机名不可重复，主机名需具有识别性。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 192.168.8.136设置的主机名</span></span><br><span class="line">[root@localhost ~]# hostnamectl hostname k8s-master-01</span><br><span class="line"><span class="comment"># 192.168.8.137设置的主机名</span></span><br><span class="line">[root@localhost ~]# hostnamectl hostname k8s-node-01</span><br><span class="line"><span class="comment"># 192.168.8.138设置的主机名</span></span><br><span class="line">[root@localhost ~]# hostnamectl hostname k8s-node-02</span><br></pre></td></tr></table></figure>



<p><strong>配置hosts域名解析</strong></p>
<p>​	需在三个节点都要执行配置，写入参数需根据自身的IP和主机名进行调整。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">192.168.8.136 k8s-master-01</span></span><br><span class="line"><span class="string">192.168.8.137 k8s-node-01</span></span><br><span class="line"><span class="string">192.168.8.138 k8s-node-02</span></span><br><span class="line"><span class="string">192.168.8.135 reg.liweihu.cn</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>





<h2 id="部署运行时docker"><a href="#部署运行时docker" class="headerlink" title="部署运行时docker"></a>部署运行时docker</h2><p>​	这里我们采用的运行时是docker引擎，docker 引擎的部署我们在第一章已经介绍过了，可以参考第一章的【离线部署docker】进行部署。</p>
<p>​	我们本次采用的是docker，v1.24 之前的 Kubernetes 版本直接集成了 Docker引擎的一个组件，名为 <strong>dockershim</strong>。但是之后的版本K8S将不在替Docker搞特殊去维护他的组件了，所以把这部分三方运行时接口删除，交给第三方docker自行去维护，docker之后就将这部分运行时接口改名为<strong>CRI-Docker</strong>，所以我们只使用docker不需要他的CRI，如果想用docker作为K8S的运行时则必须要安装docker的CRI。</p>
<p>​	默认情况下，K8s使用容器运行时接口来与你所选择的容器运行时进行交互。</p>
<p>​	如果您在部署时不指定运行时，则Kubeadm会自动尝试检测您系统上已安装的运行时，方法是扫描众所周知的Unix域套接字。</p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250704102832282.png" alt="image-20250704102832282"></p>
<p>​	<strong>运行时常用套接字</strong></p>
<table>
<thead>
<tr>
<th>运行时</th>
<th>默认Linux中的套接字</th>
</tr>
</thead>
<tbody><tr>
<td>cri-dockerd</td>
<td>&#x2F;run&#x2F;cri-dockerd.sock</td>
</tr>
<tr>
<td>containerd</td>
<td>&#x2F;run&#x2F;containerd&#x2F;containerd.sock</td>
</tr>
<tr>
<td>CRI-O</td>
<td>&#x2F;var&#x2F;run&#x2F;crio&#x2F;crio.sock</td>
</tr>
</tbody></table>
<h3 id="CRI-Docker部署"><a href="#CRI-Docker部署" class="headerlink" title="CRI-Docker部署"></a>CRI-Docker部署</h3><p><strong>CRI-Docker下载地址</strong>：<a target="_blank" rel="noopener" href="https://github.com/Mirantis/cri-dockerd/releases">https://github.com/Mirantis/cri-dockerd/releases</a></p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250704112451966.png" alt="image-20250704112451966"></p>
<p><strong>CRI-Docker.service启动文件下载地址</strong>：<a target="_blank" rel="noopener" href="https://github.com/Mirantis/cri-dockerd/blob/master/packaging/systemd/cri-docker.service">https://github.com/Mirantis/cri-dockerd/blob/master/packaging/systemd/cri-docker.service</a></p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250704112607046.png" alt="image-20250704112607046"></p>
<p><strong>cri-docker.socket启动文件下载地址</strong>：<a target="_blank" rel="noopener" href="https://github.com/Mirantis/cri-dockerd/blob/master/packaging/systemd/cri-docker.socket">https://github.com/Mirantis/cri-dockerd/blob/master/packaging/systemd/cri-docker.socket</a></p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250704144053145.png" alt="image-20250704144053145"></p>
<p><strong>解压压缩包</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压二进制文件，并移动到PATH工作目录</span></span><br><span class="line">[root@k8s-master-01 softapp]# tar -zxvf /opt/softapp/cri-dockerd-0.4.0.amd64.tgz --strip-components=1 -C /usr/local/bin/ &amp;&amp; <span class="built_in">chmod</span> 775 /usr/local/bin/cri-dockerd</span><br><span class="line"><span class="comment"># 创建service文件用于systemd守护进程</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#为service文件授权775</span></span><br><span class="line">[root@k8s-master-01 softapp]# <span class="built_in">chmod</span> 775 /etc/systemd/system/cri-docker.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将cir-docker已守护进程的方式启动</span></span><br><span class="line">[root@k8s-master-01 softapp]# </span><br><span class="line">[root@k8s-master-01 softapp]# </span><br><span class="line">[root@k8s-master-01 softapp]# </span><br></pre></td></tr></table></figure>



<p><strong>创建systemd守护进程</strong></p>
<ul>
<li><strong>cri-docker.service</strong>守护进程配置文件</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 softapp]# <span class="built_in">cat</span> &gt; /etc/systemd/system/cri-docker.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=CRI Interface for Docker Application Container Engine</span></span><br><span class="line"><span class="string">Documentation=https://docs.mirantis.com</span></span><br><span class="line"><span class="string">After=network-online.target firewalld.service docker.service</span></span><br><span class="line"><span class="string">Wants=network-online.target</span></span><br><span class="line"><span class="string">Requires=cri-docker.socket</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">Type=notify</span></span><br><span class="line"><span class="string">ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint fd://</span></span><br><span class="line"><span class="string">ExecReload=/bin/kill -s HUP $MAINPID</span></span><br><span class="line"><span class="string">TimeoutSec=0</span></span><br><span class="line"><span class="string">RestartSec=2</span></span><br><span class="line"><span class="string">Restart=always</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Note that StartLimit* options were moved from &quot;Service&quot; to &quot;Unit&quot; in systemd 229.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Both the old, and new location are accepted by systemd 229 and up, so using the old location</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># to make them work for either version of systemd.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">StartLimitBurst=3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Both the old, and new name are accepted by systemd 230 and up, so using the old name to make</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># this option work for either version of systemd.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">StartLimitInterval=60s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Having non-zero Limit*s causes performance problems due to accounting overhead</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># in the kernel. We recommend using cgroups to do container-local accounting.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">LimitNOFILE=infinity</span></span><br><span class="line"><span class="string">LimitNPROC=infinity</span></span><br><span class="line"><span class="string">LimitCORE=infinity</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Comment TasksMax if your systemd version does not support it.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Only systemd 226 and above support this option.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">TasksMax=infinity</span></span><br><span class="line"><span class="string">Delegate=yes</span></span><br><span class="line"><span class="string">KillMode=process</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p><strong>cri-docker.socket</strong>守护进程配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 softapp]# <span class="built_in">cat</span> &gt; /etc/systemd/system/cri-docker.socket &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=CRI Docker Socket for the API</span></span><br><span class="line"><span class="string">PartOf=cri-docker.service</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Socket]</span></span><br><span class="line"><span class="string">ListenStream=%t/cri-dockerd.sock</span></span><br><span class="line"><span class="string">SocketMode=0660</span></span><br><span class="line"><span class="string">SocketUser=root</span></span><br><span class="line"><span class="string">SocketGroup=docker</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=sockets.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>



<p>​	<strong>修改守护进程配置文件</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 softapp]# sed -i -e <span class="string">&#x27;s,/usr/bin/cri-dockerd --container-runtime-endpoint fd://,/usr/local/bin/cri-dockerd --container-runtime-endpoint fd:// --network-plugin=cni --pod-infra-container-image=reg.liweihu.cn/google_containers/pause:3.10,&#x27;</span> /etc/systemd/system/cri-docker.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将socket修改为root组</span></span><br><span class="line">[root@k8s-master-01 system]# sed -i -e <span class="string">&#x27;s,docker,root,&#x27;</span> /etc/systemd/system/cri-docker.socket</span><br><span class="line">[root@k8s-master-01 system]# sed -i -e <span class="string">&#x27;s,%t/cri-rootd.sock,/run/cri-dockerd.sock,&#x27;</span> /etc/systemd/system/cri-docker.socket</span><br></pre></td></tr></table></figure>



<p>​	<strong>启动cri-docker</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 system]# <span class="built_in">chmod</span> 775 /etc/systemd/system/cri-docker.s*</span><br><span class="line">[root@k8s-master-01 system]# systemctl daemon-reload </span><br><span class="line">[root@k8s-master-01 system]# systemctl <span class="built_in">enable</span> --now cri-docker.service</span><br></pre></td></tr></table></figure>









<h2 id="部署kubeadm、kubelet、kubect"><a href="#部署kubeadm、kubelet、kubect" class="headerlink" title="部署kubeadm、kubelet、kubect"></a>部署kubeadm、kubelet、kubect</h2><p>​	下载地址：<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.33/rpm/x86_64/?spm=a2c6h.25603864.0.0.70ef7af3yMGs1u">https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.33/rpm/x86_64/?spm=a2c6h.25603864.0.0.70ef7af3yMGs1u</a></p>
<p>​	分别把这五个软件包分别下载最新版本</p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250704152754075.png" alt="image-20250704152754075"></p>
<ul>
<li><strong>kubeadm</strong>：用于初始化集群的工具包指令。</li>
<li><strong>kubelet</strong>：在集群中的每个节点上用来启动Pod和容器等。</li>
<li><strong>kubectl</strong>：用来与集群通信的命令行工具。</li>
<li><strong>cni</strong>：kubelet的依赖程序。</li>
<li><strong>tools</strong>：kubeadm的依赖程序</li>
</ul>
<p>​	<strong>注意：您需要确保它们与通过kubeadm安装的控制平面版本相匹配。不然可能会导致一些预料之外的错误。然而控制平面与kubelet之间相差一个次要版本不一致是支持的，但kubelet的版本不可以超过API服务器的版本。例如1.7.0版本的kubelet可以兼容1.8.0本版本的API，1.8.0的API不能兼容1.7.0的kubelet。</strong></p>
<p>​	<strong>所以为了避免出现不可预料的问题，还是建议尽量所有组件统一版本。</strong></p>
<p>​	<strong>conntrack-tools及相关依赖下载地址</strong>：<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/redhat/rhel/rhel-9-beta/appstream/x86_64/Packages/?spm=a2c6h.25603864.0.0.6192773eKiz0x9">https://mirrors.aliyun.com/redhat/rhel/rhel-9-beta/appstream/x86_64/Packages/?spm=a2c6h.25603864.0.0.6192773eKiz0x9</a></p>
<p>​	<strong>同一下载界面需要下载以下软件包：<code>libnetfilter_cthelper</code>、<code>libnetfilter_cttimeout</code>、<code>libnetfilter_queue</code>，例如下图，通过浏览器CTRL+F进行搜索下载</strong></p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250704155507533.png" alt="image-20250704155507533"></p>
<h3 id="部署相关组件"><a href="#部署相关组件" class="headerlink" title="部署相关组件"></a>部署相关组件</h3><p>​	软件包下载并上传至三个节点，最后一次按照顺序执行rpm安装程序。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 softapp]# rpm -ivh libnetfilter*.rpm</span><br><span class="line">[root@k8s-master-01 softapp]# rpm -ivh conntrack-tools-1.4.5-9.el9.x86_64.rpm </span><br><span class="line">[root@k8s-master-01 softapp]# rpm -ivh kubernetes-cni-1.6.0-150500.1.1.x86_64.rpm cri-tools-1.33.0-150500.1.1.x86_64.rpm</span><br><span class="line">[root@k8s-master-01 softapp]# rpm -ivh kubeadm-1.33.2-150500.1.1.x86_64.rpm kubectl-1.33.2-150500.1.1.x86_64.rpm kubelet-1.33.2-150500.1.1.x86_64.rpm</span><br><span class="line"><span class="comment"># 加入自启</span></span><br><span class="line">[root@k8s-master-01 softapp]# systemctl <span class="built_in">enable</span> --now kubelet.service</span><br></pre></td></tr></table></figure>

<p>​	验证kubeadm、kubelet、kubectl版本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 softapp]# kubeadm version</span><br><span class="line">[root@k8s-master-01 softapp]# kubectl version</span><br><span class="line">[root@k8s-master-01 softapp]# kubelet --version</span><br></pre></td></tr></table></figure>



<p><strong>添加命令补全功能</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 softapp]# kubectl completion bash &gt; /etc/bash_completion.d/kubectl</span><br><span class="line">[root@k8s-master-01 softapp]# kubeadm completion bash &gt; /etc/bash_completion.d/kubeadm</span><br><span class="line">[root@k8s-master-01 softapp]# <span class="built_in">source</span> /etc/bash_completion.d/kubectl</span><br><span class="line">[root@k8s-master-01 softapp]# <span class="built_in">source</span> /etc/bash_completion.d/kubeadm</span><br></pre></td></tr></table></figure>





<h2 id="初始化集群"><a href="#初始化集群" class="headerlink" title="初始化集群"></a>初始化集群</h2><p>​	通过具有外网的Habor主机拉取所需镜像，如果您的Harbor不具备外网，则可以先使用您具备外网的docker将镜像拉取到本地，然后通过docker save和docker load将镜像保存成tar文件再导入进您的Harbor主机中。</p>
<p><strong>拉取镜像</strong></p>
<p>​	harbor主机上执行拉取镜像的任务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@reg ~]# docker pull registry.aliyuncs.com/google_containers/kube-apiserver:v1.33.0</span><br><span class="line">[root@reg ~]# docker pull registry.aliyuncs.com/google_containers/kube-controller-manager:v1.33.0</span><br><span class="line">[root@reg ~]# docker pull registry.aliyuncs.com/google_containers/kube-proxy:v1.33.0</span><br><span class="line">[root@reg ~]# docker pull registry.aliyuncs.com/google_containers/kube-scheduler:v1.33.0</span><br><span class="line">[root@reg ~]# docker pull registry.aliyuncs.com/google_containers/etcd:3.5.21-0</span><br><span class="line">[root@reg ~]# docker pull registry.aliyuncs.com/google_containers/pause:3.10</span><br><span class="line">[root@reg ~]# docker pull registry.aliyuncs.com/google_containers/coredns:v1.12.0</span><br></pre></td></tr></table></figure>



<p><strong>为镜像重新打上新的标签</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@reg ~]# docker tag registry.aliyuncs.com/google_containers/kube-apiserver:v1.33.0 reg.liweihu.cn/google_containers/kube-apiserver:v1.33.0</span><br><span class="line">[root@reg ~]# docker tag registry.aliyuncs.com/google_containers/kube-proxy:v1.33.0 reg.liweihu.cn/google_containers/kube-proxy:v1.33.0</span><br><span class="line">[root@reg ~]# docker tag registry.aliyuncs.com/google_containers/kube-controller-manager:v1.33.0 reg.liweihu.cn/google_containers/kube-controller-manager:v1.33.0</span><br><span class="line">[root@reg ~]# docker tag registry.aliyuncs.com/google_containers/kube-scheduler:v1.33.0 reg.liweihu.cn/google_containers/kube-scheduler:v1.33.0</span><br><span class="line">[root@reg ~]# docker tag registry.aliyuncs.com/google_containers/etcd:3.5.21-0 reg.liweihu.cn/google_containers/etcd:3.5.21-0</span><br><span class="line">[root@reg ~]# docker tag registry.aliyuncs.com/google_containers/pause:3.10 reg.liweihu.cn/google_containers/pause:3.10</span><br><span class="line">[root@reg ~]# docker tag registry.aliyuncs.com/google_containers/coredns:v1.12.0 reg.liweihu.cn/google_containers/coredns:v1.12.0</span><br></pre></td></tr></table></figure>



<p><strong>上传Harbor仓库</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@reg ~]# docker push reg.liweihu.cn/google_containers/kube-apiserver:v1.33.0</span><br><span class="line">[root@reg ~]# docker push reg.liweihu.cn/google_containers/kube-scheduler:v1.33.0</span><br><span class="line">[root@reg ~]# docker push reg.liweihu.cn/google_containers/kube-controller-manager:v1.33.0</span><br><span class="line">[root@reg ~]# docker push reg.liweihu.cn/google_containers/kube-proxy:v1.33.0</span><br><span class="line">[root@reg ~]# docker push reg.liweihu.cn/google_containers/etcd:3.5.21-0</span><br><span class="line">[root@reg ~]# docker push reg.liweihu.cn/google_containers/pause:3.10</span><br><span class="line">[root@reg ~]# docker push reg.liweihu.cn/google_containers/coredns:v1.12.0</span><br></pre></td></tr></table></figure>



<h3 id="Master节点集群初始化"><a href="#Master节点集群初始化" class="headerlink" title="Master节点集群初始化"></a>Master节点集群初始化</h3><p>​	Master节点上执行，他会为您将仓库中的K8s镜像拉到本地，然后为您的集群制作证书等初始化配置。</p>
<p>​	初始化完成后，输出的信息一定要保存好，这个非常重要，我们需要用它输出的命令来完成最后的操作，以及node节点的加入集群。</p>
<p>​	<strong>参数解析</strong></p>
<ul>
<li><strong>–apiserver-advertise-address</strong>：Master节点IP</li>
<li><strong>–apiserver-bind-port</strong>：Master中的API端口</li>
<li><strong>–kubernetes-version</strong>：k8s版本</li>
<li><strong>–cri-socket</strong>：运行时的sock文件路径</li>
<li><strong>–service-dns-domain</strong>：dns域</li>
<li><strong>–image-repository</strong>：镜像仓库地址</li>
<li><strong>–service-cidr</strong>：service服务发现网段</li>
<li><strong>–pod-network-cidr</strong>：pod网段</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 etc]# kubeadm init \</span><br><span class="line">--apiserver-advertise-address=192.168.8.136 \</span><br><span class="line">--apiserver-bind-port=6443 \</span><br><span class="line">--kubernetes-version=1.33.0 \</span><br><span class="line">--token-ttl=0 \</span><br><span class="line">--cri-socket=/run/cri-dockerd.sock \</span><br><span class="line">--service-dns-domain=cluster.local \</span><br><span class="line">--image-repository reg.liweihu.cn/google_containers \</span><br><span class="line">--service-cidr=10.96.0.0/12 \</span><br><span class="line">--pod-network-cidr=10.244.0.0/16</span><br><span class="line"></span><br><span class="line">[init] Using Kubernetes version: v1.33.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">	[WARNING Firewalld]: firewalld is active, please ensure ports [6443 10250] are open or your cluster may not <span class="keyword">function</span> correctly</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action beforehand using <span class="string">&#x27;kubeadm config images pull&#x27;</span></span><br><span class="line">[certs] Using certificateDir folder <span class="string">&quot;/etc/kubernetes/pki&quot;</span></span><br><span class="line">......忽略.....</span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出内容中的该条命令Master节点需要创建的在用户家目录下的一些配置文件</span></span><br><span class="line">  <span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  <span class="built_in">sudo</span> <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  <span class="built_in">sudo</span> <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, <span class="keyword">if</span> you are the root user, you can run:</span><br><span class="line"><span class="comment"># 输出内容中的该条命令Master节点需要创建的在用户家目录下的一些配置文件</span></span><br><span class="line">  <span class="built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can <span class="built_in">join</span> any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出内容中的该条命令是Node节点加入集群的命令需要再Node节点执行</span></span><br><span class="line">kubeadm <span class="built_in">join</span> 192.168.8.136:6443 --token 6v7c7k.9hc5wow978c3xkbx \</span><br><span class="line">	--discovery-token-ca-cert-hash sha256:5b2af6b3c07f793f1f863203624d26c187bbc425b12de797616bf9fbbc3bed4c</span><br></pre></td></tr></table></figure>



<p>​	根据输出的提示，Master节点执行它提供的命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于我们全程都是使用root进行操作的，所以root用户执行</span></span><br><span class="line">[root@k8s-master-01 etc]# <span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">[root@k8s-master-01 etc]# <span class="built_in">sudo</span> <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">[root@k8s-master-01 etc]# <span class="built_in">sudo</span> <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"><span class="comment"># root用户需要执行该条命令  </span></span><br><span class="line">[root@k8s-master-01 etc]# <span class="built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf</span><br></pre></td></tr></table></figure>

<p>​	执行完成后，我们可以先认识一下<code>kubectl get nodes</code>这条命令，该命令的作用是查看集群下分别由哪些节点，以及各节点的角色、状态、版本等。</p>
<p>​	kubectl为k8s控制集群的命令。get获取，nodes节点。可以看到当前就只有一个控制平面的节点，并且他的状态是NotReady（未启动的）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 etc]# kubectl get  nodes</span><br><span class="line">NAME            STATUS     ROLES           AGE   VERSION</span><br><span class="line">k8s-master-01   NotReady   control-plane   14m   v1.33.2</span><br></pre></td></tr></table></figure>



<h3 id="创建secret"><a href="#创建secret" class="headerlink" title="创建secret"></a>创建secret</h3><p>​	Secret是k8s中非常使用的一个功能，例如我们在初始化集群的时候我们把存放K8s镜像的仓库，设置为私有镜像</p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250708173536817.png" alt="image-20250708173536817"></p>
<p>​	当我们进行初始化kubeadm的时候提示就会提示如下图的错误，拉取镜像失败，仓库是未经授权的错误，但是我们docke login和pull都能正常从这个私有仓库拉镜像下来，那是因为我们在docker login的时候是用了admin这个用户去登录的，docker使用了管理员用户，他肯定是可以拉下来的，但是我们的kubeadm使用的可不一定是管理员，所以造成这样的异常，这里我们可以把仓库设置为公开即可。</p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250708172539078.png" alt="image-20250708172539078"></p>
<p>​	如果我们公司内部为了安全的保护内部镜像不被泄露，在k8s创建pod从私有仓库拉还是会遇到这样的问题，那这个时候我们就要介绍一下K8s中的Secret资源了。</p>
<p><strong>创建Secret</strong></p>
<p>​	命令解析：</p>
<ul>
<li><strong>kubectl</strong>：为控制集群的二进制命令。</li>
<li><strong>create</strong>：表示该操作为创建某个资源。</li>
<li><strong>secret</strong>：创建的资源类型为secret的选项。</li>
<li><strong>docker-registry</strong>：该资源下的子类别，用于docker仓库的选项。</li>
<li><strong>registry-secret-liweihu</strong>：资源名称参数。</li>
<li><strong>docker-server</strong>：仓库地址参数。</li>
<li><strong>docker-username</strong>：仓库的用户名参数。</li>
<li><strong>docker-password</strong>：仓库的密码参数</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 etc]# kubectl create secret docker-registry registry-secret-liweihu --docker-server=reg.liweihu.cn --docker-username=admin --docker-password=admin</span><br><span class="line">secret/registry-secret-liweihu created</span><br><span class="line"><span class="comment"># 验证是否添加</span></span><br><span class="line">[root@k8s-master-01 etc]# kubectl get secrets </span><br><span class="line">NAME                      TYPE                             DATA   AGE</span><br><span class="line">registry-secret-liweihu   kubernetes.io/dockerconfigjson   1      17s</span><br><span class="line">[root@k8s-master-01 etc]#</span><br></pre></td></tr></table></figure>

<p>​	这样就创建完成了，这个验证我们到后面章节再为大家展示创建与没创建的效果，本章节了解该内容即可，便于后续的操作。</p>
<h3 id="将Node节点添加至集群中"><a href="#将Node节点添加至集群中" class="headerlink" title="将Node节点添加至集群中"></a>将Node节点添加至集群中</h3><p>​	前面我们创建了集群，目前集群里仅有一个控制平面节点（Master），接下来我们要将Node节点加入集群，这里要使用到我们初始化集群时保存的如下命令再node节点进行操作，添加节点。</p>
<p>​	<strong>两个节点执行的命令都是一样的，依次有序执行即可。</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-01 system]# kubeadm <span class="built_in">join</span> 192.168.8.136:6443 --token 6v7c7k.9hc5wow978c3xkbx      --discovery-token-ca-cert-hash sha256:5b2af6b3c07f793f1f863203624d26c187bbc425b12de797616bf9fbbc3bed4c</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the <span class="string">&quot;kubeadm-config&quot;</span> ConfigMap <span class="keyword">in</span> namespace <span class="string">&quot;kube-system&quot;</span>...</span><br><span class="line">[preflight] Use <span class="string">&#x27;kubeadm init phase upload-config --config your-config-file&#x27;</span> to re-upload it.</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">&quot;/var/lib/kubelet/config.yaml&quot;</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-check] Waiting <span class="keyword">for</span> a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s</span><br><span class="line">[kubelet-check] The kubelet is healthy after 1.503844186s</span><br><span class="line">[kubelet-start] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run <span class="string">&#x27;kubectl get nodes&#x27;</span> on the control-plane to see this node <span class="built_in">join</span> the cluster.</span><br><span class="line"></span><br><span class="line">[root@k8s-node-01 system]#</span><br></pre></td></tr></table></figure>

<p>​	添加完成后，我们再回来Master节点，查看集群节点就可以看到另外两台node已经现实出来了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 etc]# kubectl get nodes</span><br><span class="line">NAME            STATUS     ROLES           AGE     VERSION</span><br><span class="line">k8s-master-01   NotReady   control-plane   137m    v1.33.2</span><br><span class="line">k8s-node-01     NotReady   &lt;none&gt;          5m40s   v1.33.2</span><br><span class="line">k8s-node-02     NotReady   &lt;none&gt;          43s     v1.33.2</span><br></pre></td></tr></table></figure>





<h2 id="Calico网络部署"><a href="#Calico网络部署" class="headerlink" title="Calico网络部署"></a>Calico网络部署</h2><h3 id="软件包下载"><a href="#软件包下载" class="headerlink" title="软件包下载"></a><strong>软件包下载</strong></h3><p>​	<strong>下载地址：</strong><code>https://github.com/projectcalico/calico/releases/tag/v3.30.2</code></p>
<p><img src="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/image-20250710102042170.png" alt="image-20250710102042170"></p>
<h3 id="上传并部署Calico"><a href="#上传并部署Calico" class="headerlink" title="上传并部署Calico"></a>上传并部署Calico</h3><p>​	解压完成后，进入解压目录中的images目录，将里面的镜像文件导入到本地镜像仓库。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 images]# <span class="built_in">pwd</span></span><br><span class="line">/opt/softapp/release-v3.30.2/images</span><br><span class="line">[root@k8s-master-01 images]# ll</span><br><span class="line">总用量 1007816</span><br><span class="line">-rw-------. 1 1001 1001 162432000  6月 20 06:57 calico-cni.tar</span><br><span class="line">-rw-------. 1 1001 1001  91260416  6月 20 06:57 calico-dikastes.tar</span><br><span class="line">-rw-------. 1 1001 1001 152131072  6月 20 06:57 calico-flannel-migration-controller.tar</span><br><span class="line">-rw-------. 1 1001 1001 121548288  6月 20 06:57 calico-kube-controllers.tar</span><br><span class="line">-rw-------. 1 1001 1001 407298560  6月 20 06:57 calico-node.tar</span><br><span class="line">-rw-------. 1 1001 1001  12103168  6月 20 06:57 calico-pod2daemon.tar</span><br><span class="line">-rw-------. 1 1001 1001  85215744  6月 20 06:57 calico-typha.tar</span><br><span class="line"><span class="comment"># 将镜像导入本地镜像仓库</span></span><br><span class="line">[root@k8s-master-01 images]# docker load -i calico-cni.tar</span><br><span class="line">[root@k8s-master-01 images]# docker load -i calico-dikastes.tar</span><br><span class="line">[root@k8s-master-01 images]# docker load -i calico-flannel-migration-controller.tar</span><br><span class="line">[root@k8s-master-01 images]# docker load -i calico-kube-controllers.tar</span><br><span class="line">[root@k8s-master-01 images]# docker load -i calico-node.tar</span><br><span class="line">[root@k8s-master-01 images]# docker load -i calico-pod2daemon.tar</span><br><span class="line">[root@k8s-master-01 images]# docker load -i calico-typha.tar</span><br><span class="line"><span class="comment"># 查看镜像是否已导入本地镜像仓库</span></span><br><span class="line">[root@k8s-master-01 images]# docker images </span><br><span class="line">REPOSITORY                                                 TAG        IMAGE ID       CREATED         SIZE</span><br><span class="line">calico/typha                                               v3.30.2    b3baa600c7ff   3 weeks ago     85.2MB</span><br><span class="line">calico/pod2daemon-flexvol                                  v3.30.2    639615519fa6   3 weeks ago     12MB</span><br><span class="line">calico/node                                                v3.30.2    cc52550d767f   3 weeks ago     405MB</span><br><span class="line">calico/flannel-migration-controller                        v3.30.2    0f62b640dd7c   3 weeks ago     152MB</span><br><span class="line">calico/kube-controllers                                    v3.30.2    761b294e2655   3 weeks ago     122MB</span><br><span class="line">calico/cni                                                 v3.30.2    77a357d0d33e   3 weeks ago     162MB</span><br><span class="line">calico/dikastes                                            v3.30.2    b3e1c212267f   3 weeks ago     91.2MB</span><br></pre></td></tr></table></figure>



<p>​	为导入进本地镜像仓库的calico镜像重新打上新标签，便于上传Harbor私有镜像仓库。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新打标签</span></span><br><span class="line">[root@k8s-master-01 manifests]# docker tag calico/cni:v3.30.2 reg.liweihu.cn/calico/cni:v3.30.2 </span><br><span class="line">[root@k8s-master-01 manifests]# docker tag calico/node:v3.30.2 reg.liweihu.cn/calico/node:v3.30.2 </span><br><span class="line">[root@k8s-master-01 manifests]# docker tag calico/kube-controllers:v3.30.2 reg.liweihu.cn/calico/kube-controllers:v3.30.2 </span><br><span class="line">[root@k8s-master-01 manifests]# docker tag calico/pod2daemon-flexvol:v3.30.2 reg.liweihu.cn/calico/pod2daemon-flexvol:v3.30.2 </span><br><span class="line">[root@k8s-master-01 manifests]# docker tag calico/dikastes:v3.30.2 reg.liweihu.cn/calico/dikastes:v3.30.2 </span><br><span class="line">[root@k8s-master-01 manifests]# docker tag calico/typha:v3.30.2 reg.liweihu.cn/calico/typha:v3.30.2 </span><br><span class="line">[root@k8s-master-01 manifests]# docker tag calico/flannel-migration-controller:v3.30.2 reg.liweihu.cn/calico/flannel-migration-controller:v3.30.2 </span><br></pre></td></tr></table></figure>



<p>​	将重新打好标签的镜像上传本地镜像仓库，在此操作前，需先在Harbor创建好一个公开的calico仓库，仓库名称具体根据你的标签定义的仓库名称来自行定于。</p>
<p>​	<strong>标签组成解析</strong></p>
<ul>
<li>reg.liweihu.cn&#x2F;：镜像仓库地址（域名）</li>
<li>calico&#x2F;：仓库名称</li>
<li>cni:v3.30.2：镜像名:版本号</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上传镜像仓库</span></span><br><span class="line">[root@k8s-master-01 manifests]# docker push reg.liweihu.cn/calico/cni:v3.30.2</span><br><span class="line">[root@k8s-master-01 manifests]# docker push reg.liweihu.cn/calico/node:v3.30.2</span><br><span class="line">[root@k8s-master-01 manifests]# docker push reg.liweihu.cn/calico/kube-controllers:v3.30.2</span><br><span class="line">[root@k8s-master-01 manifests]# docker push reg.liweihu.cn/calico/pod2daemon-flexvol:v3.30.2</span><br><span class="line">[root@k8s-master-01 manifests]# docker push reg.liweihu.cn/calico/dikastes:v3.30.2</span><br><span class="line">[root@k8s-master-01 manifests]# docker push reg.liweihu.cn/calico/typha:v3.30.2</span><br><span class="line">[root@k8s-master-01 manifests]# docker push reg.liweihu.cn/calico/flannel-migration-controller:v3.30.2</span><br></pre></td></tr></table></figure>

<p>​	进入到软件包解压后的manifests目录，修改yaml文件镜像拉取的地址，默认是dockerHub的公有镜像仓库，但是由于限制的问题，我们无法从国内获取，所以需要离线从我们的私有仓库中获取镜像。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 manifests]# <span class="built_in">pwd</span></span><br><span class="line">/opt/softapp/release-v3.30.2/manifests</span><br><span class="line"><span class="comment"># 查询calico所需镜像并将镜像仓库修改为私有仓库的地址</span></span><br><span class="line"><span class="comment"># 这里自行vim或vi进入文本自行修改，由于各版本不同，这里就不用sed来写了，自行vim修改避免内容格式混乱</span></span><br><span class="line"><span class="comment"># 修改前</span></span><br><span class="line">[root@k8s-master-01 manifests]# <span class="built_in">cat</span> calico.yaml |grep image:</span><br><span class="line">          image: docker.io/calico/cni:v3.30.2</span><br><span class="line">          image: docker.io/calico/cni:v3.30.2</span><br><span class="line">          image: docker.io/calico/node:v3.30.2</span><br><span class="line">          image: docker.io/calico/node:v3.30.2</span><br><span class="line">          image: docker.io/calico/kube-controllers:v3.30.2</span><br><span class="line"><span class="comment"># 修改后</span></span><br><span class="line">[root@k8s-master-01 manifests]# <span class="built_in">cat</span> calico.yaml |grep image:</span><br><span class="line">          image: reg.liweihu.cn/calico/cni:v3.30.2</span><br><span class="line">          image: reg.liweihu.cn/calico/cni:v3.30.2</span><br><span class="line">          image: reg.liweihu.cn/calico/node:v3.30.2</span><br><span class="line">          image: reg.liweihu.cn/calico/node:v3.30.2</span><br><span class="line">          image: reg.liweihu.cn/calico/kube-controllers:v3.30.2</span><br><span class="line"><span class="comment"># 修改calico的podIP网段，这里要与kubeadm分配的PodIP一致，否则calico无法正常分配IP</span></span><br><span class="line">[root@k8s-master-01 manifests]# <span class="built_in">cat</span> custom-resources.yaml | grep  cidr:</span><br><span class="line">      cidr: 10.244.0.0/16</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装calico</span></span><br><span class="line">[root@k8s-master-01 manifests]# kubectl apply -f custom-resources.yaml</span><br><span class="line">[root@k8s-master-01 manifests]# kubectl apply -f tigera-operator.yaml</span><br><span class="line">[root@k8s-master-01 manifests]# kubectl apply -f calico.yaml</span><br><span class="line">poddisruptionbudget.policy/calico-kube-controllers created</span><br><span class="line">serviceaccount/calico-kube-controllers created</span><br><span class="line">serviceaccount/calico-node created</span><br><span class="line">serviceaccount/calico-cni-plugin created</span><br><span class="line">configmap/calico-config created</span><br><span class="line">....忽略....</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-node created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-cni-plugin created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-tier-getter created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-node created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-cni-plugin created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-tier-getter created</span><br><span class="line">daemonset.apps/calico-node created</span><br><span class="line">deployment.apps/calico-kube-controllers created</span><br></pre></td></tr></table></figure>



<p>​	安装完成calico后，检查各节点是否处于Ready允许状态。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 manifests]# kubectl get nodes</span><br><span class="line">NAME            STATUS   ROLES           AGE     VERSION</span><br><span class="line">k8s-master-01   Ready    control-plane   3d1h    v1.33.2</span><br><span class="line">k8s-node-01     Ready    &lt;none&gt;          2d23h   v1.33.2</span><br><span class="line">k8s-node-02     Ready    &lt;none&gt;          2d23h   v1.33.2</span><br></pre></td></tr></table></figure>

<p>​	检查所有Pod是否运行正常，这里我们可以看到，以及calico为这些Pod分配的IP。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 manifests]# kubectl get pods -A -o wide</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS      AGE     IP               NODE            NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   calico-kube-controllers-7f59498f59-kf5nn   1/1     Running   2 (24m ago)   24h     10.244.151.136   k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-7ndvs                          1/1     Running   2 (24m ago)   24h     192.168.8.137    k8s-node-01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-l4rfm                          1/1     Running   2 (24m ago)   24h     192.168.8.136    k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-ls56h                          1/1     Running   2 (24m ago)   24h     192.168.8.138    k8s-node-02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-dc6b59956-72kvq                    1/1     Running   2 (24m ago)   3d1h    10.244.151.135   k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-dc6b59956-bfgfb                    1/1     Running   2 (24m ago)   3d1h    10.244.151.137   k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-k8s-master-01                         1/1     Running   4 (24m ago)   3d1h    192.168.8.136    k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-k8s-master-01               1/1     Running   4 (24m ago)   3d1h    192.168.8.136    k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-k8s-master-01      1/1     Running   4 (24m ago)   3d1h    192.168.8.136    k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-ggxph                           1/1     Running   3 (24m ago)   2d23h   192.168.8.138    k8s-node-02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-hb9dg                           1/1     Running   3 (24m ago)   2d23h   192.168.8.137    k8s-node-01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-rv6rk                           1/1     Running   4 (24m ago)   3d1h    192.168.8.136    k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-k8s-master-01               1/1     Running   4 (24m ago)   3d1h    192.168.8.136    k8s-master-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="为Node节点打标签"><a href="#为Node节点打标签" class="headerlink" title="为Node节点打标签"></a>为Node节点打标签</h2><p>​	我们部署完成后发现，我们的master节点是具有<code>control-plane</code>（控制平面）的角色标签，但是我们另外的两个node是<code>none</code>（空），为了便于管理辨认最好将其打上标签，已区分各节点的角色关系。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-01 ~]# kubectl get nodes</span><br><span class="line">NAME            STATUS   ROLES           AGE     VERSION</span><br><span class="line">k8s-master-01   Ready    control-plane   5d18h   v1.33.2</span><br><span class="line">k8s-node-01     Ready    node            5d16h   v1.33.2</span><br><span class="line">k8s-node-02     Ready    node            5d16h   v1.33.2</span><br><span class="line"><span class="comment"># label、nodes选项，role.kubernetes.io/node=资源记标签</span></span><br><span class="line">[root@k8s-master-01 ~]# kubectl label nodes k8s-node-01 k8s-node-02 node-role.kubernetes.io/node=</span><br></pre></td></tr></table></figure>



<h2 id="加入Node节点"><a href="#加入Node节点" class="headerlink" title="加入Node节点"></a>加入Node节点</h2><p>​	如果后续2台node已经支撑不了业务的运行，需要增加node节点，但是最开始的加入集群的语句已经丢了，我们可以通过一下方式获取新的join参数。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建token，并print打印join命令参数</span></span><br><span class="line">[root@k8s-master-01 ~]# kubeadm token create --print-join-command</span><br><span class="line">kubeadm <span class="built_in">join</span> 192.168.8.136:6443 --token fuag1e.rlwcwz93roobuts8 --discovery-token-ca-cert-hash sha256:5b2af6b3c07f793f1f863203624d26c187bbc425b12de797616bf9fbbc3bed4cxxxxxxxxxx kubeadm token create --print-join-command[root@k8s-master-01 ~]# kubeadm token create --print-join-commandkubeadm <span class="built_in">join</span> 192.168.8.136:6443 --token fuag1e.rlwcwz93roobuts8 --discovery-token-ca-cert-hash sha256:5b2af6b3c07f793f1f863203624d26c187bbc425b12de797616bf9fbbc3bed4cbash</span><br></pre></td></tr></table></figure>



<h2 id="重置集群"><a href="#重置集群" class="headerlink" title="重置集群"></a>重置集群</h2><p>​	如果因为某种原因您想删除集群重新进行部署，可通过一下方式进行删除，删除完成后即可重新进行初始化集群。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#清除集群中的运行时</span></span><br><span class="line">[root@k8s-master-01 ~]# kubeadm reset --cri-socket=unix:///var/run/cri-dockerd.sock</span><br><span class="line"><span class="comment"># 手动删除K8S相关配置文件</span></span><br><span class="line">[root@k8s-master-01 ~]# <span class="built_in">rm</span> -rf /etc/cni/net.d</span><br><span class="line">[root@k8s-master-01 ~]# iptables -F</span><br><span class="line">[root@k8s-master-01 ~]# <span class="built_in">rm</span> -rf <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure>



<p><strong>至此Kubernetes单节点集群已部署完成，离线部署话可以通过二进制的方式进行部署，所有组件通过守护进程进行管理，如果想了解二进制方式的部署可参考我的CSDN文档：</strong><code>https://blog.csdn.net/qq_42658764/article/details/137954292</code></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">李维虎</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/">http://example.com/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">此文章版权归博主所有，如有转载，请注明来自原作者，联系方式（微信）：a1253582301</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Kubernetes/">Kubernetes</a></div><div class="post-share"><div class="social-share" data-image="/img/doc_img/Kubernetes.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wx.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wx.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/zfb.jpg" target="_blank"><img class="post-qr-code-img" src="/img/zfb.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/06/05/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%B8%80%E7%AB%A0/" title="CKA-kubernetes-第一章"><img class="cover" src="/img/doc_img/Kubernetes.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">CKA-kubernetes-第一章</div></div><div class="info-2"><div class="info-item-1">...</div></div></div></a><a class="pagination-related" href="/2025/07/14/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%B8%89%E7%AB%A0/" title="CKA-kubernetes-第三章"><img class="cover" src="/img/doc_img/Kubernetes.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">CKA-kubernetes-第三章</div></div><div class="info-2"><div class="info-item-1">Kubectl语法​	一旦K8s集群搭建完成后，我们就可以再其部署容器化应用。在此之前我们需要先了解，kubectl的语法，以便后续管理和维护k8s集群。 ​	kubectl命令的常见格式是：kubectl action resource [parameter]。  kubectl：二进制执行文件。 action：操作选项。 resource：资源类型。 parameter（可选）：参数。  ​	这会对指定的资源（类似node或deployment）执行指定的操作（类似create、describe或delete）。您可以再子命令后面使用 --help获取可能参数相关的更多信息。kubectl get nodes...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/14/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%B8%89%E7%AB%A0/" title="CKA-kubernetes-第三章"><img class="cover" src="/img/doc_img/Kubernetes.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-14</div><div class="info-item-2">CKA-kubernetes-第三章</div></div><div class="info-2"><div class="info-item-1">Kubectl语法​	一旦K8s集群搭建完成后，我们就可以再其部署容器化应用。在此之前我们需要先了解，kubectl的语法，以便后续管理和维护k8s集群。 ​	kubectl命令的常见格式是：kubectl action resource [parameter]。  kubectl：二进制执行文件。 action：操作选项。 resource：资源类型。 parameter（可选）：参数。  ​	这会对指定的资源（类似node或deployment）执行指定的操作（类似create、describe或delete）。您可以再子命令后面使用 --help获取可能参数相关的更多信息。kubectl get nodes...</div></div></div></a><a class="pagination-related" href="/2025/06/05/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%B8%80%E7%AB%A0/" title="CKA-kubernetes-第一章"><img class="cover" src="/img/doc_img/Kubernetes.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-05</div><div class="info-item-2">CKA-kubernetes-第一章</div></div><div class="info-2"><div class="info-item-1">...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/head/head.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">李维虎</div><div class="author-info-description">一个热爱技术分享的有志青年</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><p>欢迎来到我的<em>博客网站</em>，如对文章内容有疑惑可扫描二维码添加博主微信。</p> <p>文章来之不易，如认为文章不错请在文章底部为博主打赏,你的支持是我持续更新的动力</p> <CENTER><img src="img\index_img/wxewm.png" alt="描述文字" style="width:250px; height:250px;"></CENTER></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kubernetes%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">Kubernetes概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFKubernetes"><span class="toc-number">1.1.</span> <span class="toc-text">什么是Kubernetes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kubernetes%E7%9A%84%E5%8E%86%E5%8F%B2%E8%83%8C%E6%99%AF"><span class="toc-number">1.2.</span> <span class="toc-text">Kubernetes的历史背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kubernetes%E7%89%B9%E7%82%B9"><span class="toc-number">1.3.</span> <span class="toc-text">Kubernetes特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kubernetes%E4%BD%9C%E7%94%A8"><span class="toc-number">1.4.</span> <span class="toc-text">Kubernetes作用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kubernetes%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6"><span class="toc-number">1.5.</span> <span class="toc-text">Kubernetes整体框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E5%B9%B3%E9%9D%A2%E7%BB%84%E4%BB%B6"><span class="toc-number">1.5.1.</span> <span class="toc-text">控制平面组件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#kube-apiserver"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">kube-apiserver</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#etcd"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">etcd</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kube-scheduler"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">kube-scheduler</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kube-controller-manager"><span class="toc-number">1.5.1.4.</span> <span class="toc-text">kube-controller-manager</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cloud-controller-manager"><span class="toc-number">1.5.1.5.</span> <span class="toc-text">cloud-controller-manager</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E7%BB%84%E4%BB%B6"><span class="toc-number">1.5.2.</span> <span class="toc-text">节点组件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#kubelet"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">kubelet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kube-proxy%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">kube-proxy（可选）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6"><span class="toc-number">1.5.2.3.</span> <span class="toc-text">容器运行时</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kubernetes%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6"><span class="toc-number">1.6.</span> <span class="toc-text">Kubernetes常用插件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Core-DNS"><span class="toc-number">1.6.1.</span> <span class="toc-text">Core-DNS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Web-%E7%95%8C%E9%9D%A2%EF%BC%88%E4%BB%AA%E8%A1%A8%E7%9B%98%EF%BC%89"><span class="toc-number">1.6.2.</span> <span class="toc-text">Web 界面（仪表盘）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%B9%E5%99%A8%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7"><span class="toc-number">1.6.3.</span> <span class="toc-text">容器资源监控</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%B1%82%E9%9D%A2%E6%97%A5%E5%BF%97"><span class="toc-number">1.6.4.</span> <span class="toc-text">集群层面日志</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6"><span class="toc-number">1.6.5.</span> <span class="toc-text">网络插件</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2Kubernetes"><span class="toc-number">2.</span> <span class="toc-text">部署Kubernetes</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.1.</span> <span class="toc-text">环境介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">2.2.</span> <span class="toc-text">环境初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2%E8%BF%90%E8%A1%8C%E6%97%B6docker"><span class="toc-number">2.3.</span> <span class="toc-text">部署运行时docker</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CRI-Docker%E9%83%A8%E7%BD%B2"><span class="toc-number">2.3.1.</span> <span class="toc-text">CRI-Docker部署</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2kubeadm%E3%80%81kubelet%E3%80%81kubect"><span class="toc-number">2.4.</span> <span class="toc-text">部署kubeadm、kubelet、kubect</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6"><span class="toc-number">2.4.1.</span> <span class="toc-text">部署相关组件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E9%9B%86%E7%BE%A4"><span class="toc-number">2.5.</span> <span class="toc-text">初始化集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Master%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">2.5.1.</span> <span class="toc-text">Master节点集群初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAsecret"><span class="toc-number">2.5.2.</span> <span class="toc-text">创建secret</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86Node%E8%8A%82%E7%82%B9%E6%B7%BB%E5%8A%A0%E8%87%B3%E9%9B%86%E7%BE%A4%E4%B8%AD"><span class="toc-number">2.5.3.</span> <span class="toc-text">将Node节点添加至集群中</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Calico%E7%BD%91%E7%BB%9C%E9%83%A8%E7%BD%B2"><span class="toc-number">2.6.</span> <span class="toc-text">Calico网络部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%AF%E4%BB%B6%E5%8C%85%E4%B8%8B%E8%BD%BD"><span class="toc-number">2.6.1.</span> <span class="toc-text">软件包下载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E5%B9%B6%E9%83%A8%E7%BD%B2Calico"><span class="toc-number">2.6.2.</span> <span class="toc-text">上传并部署Calico</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BANode%E8%8A%82%E7%82%B9%E6%89%93%E6%A0%87%E7%AD%BE"><span class="toc-number">2.7.</span> <span class="toc-text">为Node节点打标签</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E5%85%A5Node%E8%8A%82%E7%82%B9"><span class="toc-number">2.8.</span> <span class="toc-text">加入Node节点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="toc-number">2.9.</span> <span class="toc-text">重置集群</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/07/14/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%B8%89%E7%AB%A0/" title="CKA-kubernetes-第三章"><img src="/img/doc_img/Kubernetes.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CKA-kubernetes-第三章"/></a><div class="content"><a class="title" href="/2025/07/14/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%B8%89%E7%AB%A0/" title="CKA-kubernetes-第三章">CKA-kubernetes-第三章</a><time datetime="2025-07-14T03:36:45.000Z" title="发表于 2025-07-14 11:36:45">2025-07-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/" title="CKA-kubernetes-第二章"><img src="/img/doc_img/Kubernetes.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CKA-kubernetes-第二章"/></a><div class="content"><a class="title" href="/2025/07/03/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%BA%8C%E7%AB%A0/" title="CKA-kubernetes-第二章">CKA-kubernetes-第二章</a><time datetime="2025-07-03T01:40:06.000Z" title="发表于 2025-07-03 09:40:06">2025-07-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/05/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%B8%80%E7%AB%A0/" title="CKA-kubernetes-第一章"><img src="/img/doc_img/Kubernetes.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CKA-kubernetes-第一章"/></a><div class="content"><a class="title" href="/2025/06/05/03-Kubernetes/CKA-kubernetes-%E7%AC%AC%E4%B8%80%E7%AB%A0/" title="CKA-kubernetes-第一章">CKA-kubernetes-第一章</a><time datetime="2025-06-05T02:38:53.000Z" title="发表于 2025-06-05 10:38:53">2025-06-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/04/01-RHCE/01-124/Linux-RHCE-124-%E7%AC%AC%E5%85%AB%E7%AB%A0%E8%8A%82/" title="Linux-RHCE-124-第八章节"><img src="/img/doc_img/RHCE_cover.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux-RHCE-124-第八章节"/></a><div class="content"><a class="title" href="/2025/06/04/01-RHCE/01-124/Linux-RHCE-124-%E7%AC%AC%E5%85%AB%E7%AB%A0%E8%8A%82/" title="Linux-RHCE-124-第八章节">Linux-RHCE-124-第八章节</a><time datetime="2025-06-04T08:24:51.000Z" title="发表于 2025-06-04 16:24:51">2025-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/05/26/01-RHCE/01-124/Linux-RHCE-124-%E7%AC%AC%E4%B8%83%E7%AB%A0%E8%8A%82/" title="Linux-RHCE-124-第七章节"><img src="/img/doc_img/RHCE_cover.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux-RHCE-124-第七章节"/></a><div class="content"><a class="title" href="/2025/05/26/01-RHCE/01-124/Linux-RHCE-124-%E7%AC%AC%E4%B8%83%E7%AB%A0%E8%8A%82/" title="Linux-RHCE-124-第七章节">Linux-RHCE-124-第七章节</a><time datetime="2025-05-26T08:59:32.000Z" title="发表于 2025-05-26 16:59:32">2025-05-26</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(img/doc_img/Kubernetes.webp);"><div id="footer-wrap"><div class="copyright">&copy;2025 By 李维虎</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div><div class="footer_custom_text">主题框架声明</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"></div><div class="aplayer no-destroy" data-id="60198" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true"> </div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="true" data-text="晚,上,好" data-fontsize="20px" data-random="true" async="async"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script>(() => {
  const destroyAplayer = () => {
    if (window.aplayers) {
      for (let i = 0; i < window.aplayers.length; i++) {
        if (!window.aplayers[i].options.fixed) {
          window.aplayers[i].destroy()
        }
      }
    }
  }

  const runMetingJS = () => {
    typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()
  }

  btf.addGlobalFn('pjaxSend', destroyAplayer, 'destroyAplayer')
  btf.addGlobalFn('pjaxComplete', loadMeting, 'runMetingJS')
})()</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>